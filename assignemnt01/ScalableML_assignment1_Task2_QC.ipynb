{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"COM6012 Assignment 1 Task2 QC\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sc.setCheckpointDir('checkpoint/')\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    lines = spark.read.text(filepath).rdd\n",
    "    parts = lines.map(lambda row: row.value.split(\",\"))\n",
    "    header = parts.first()\n",
    "    parts = parts.filter(lambda line: line != header)\n",
    "    return parts\n",
    "\n",
    "ratingsRDD = load_data(\"ml-25m/ratings.csv\").map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),rating=float(p[2]), timestamp=str(p[3])))\n",
    "ratings = spark.createDataFrame(ratingsRDD).cache()\n",
    "\n",
    "scoresRDD = load_data(\"ml-25m/genome-scores.csv\").map(lambda p: Row(movieId=int(p[0]), tagId=int(p[1]),relevance=float(p[2])))\n",
    "scores = spark.createDataFrame(scoresRDD).cache()\n",
    "\n",
    "tagsRDD = load_data(\"ml-25m/genome-tags.csv\").map(lambda p: Row(tagId=int(p[0]), tag=str(p[1])))\n",
    "tags = spark.createDataFrame(tagsRDD).cache()\n",
    "\n",
    "count_tagsRDD = load_data(\"ml-25m/tags.csv\").map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),tag=str(p[2]), timestamp=str(p[3])))\n",
    "count_tags = spark.createDataFrame(count_tagsRDD).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = spark.read.text(\"ml-25m/ratings.csv\").rdd\n",
    "parts = lines.map(lambda row: row.value.split(\",\"))\n",
    "header = parts.first()\n",
    "parts = parts.filter(lambda line: line != header)\n",
    "\n",
    "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),rating=float(p[2]), timestamp=str(p[3])))\n",
    "ratings = spark.createDataFrame(ratingsRDD).cache()\n",
    "\n",
    "lines = spark.read.text(\"ml-25m/genome-scores.csv\").rdd\n",
    "parts = lines.map(lambda row: row.value.split(\",\"))\n",
    "header = parts.first()\n",
    "parts = parts.filter(lambda line: line != header)\n",
    "\n",
    "scoresRDD = parts.map(lambda p: Row(movieId=int(p[0]), tagId=int(p[1]),relevance=float(p[2])))\n",
    "scores = spark.createDataFrame(scoresRDD).cache()\n",
    "\n",
    "lines = spark.read.text(\"ml-25m/genome-tags.csv\").rdd\n",
    "parts = lines.map(lambda row: row.value.split(\",\"))\n",
    "header = parts.first()\n",
    "parts = parts.filter(lambda line: line != header)\n",
    "\n",
    "tagsRDD = parts.map(lambda p: Row(tagId=int(p[0]), tag=str(p[1])))\n",
    "tags = spark.createDataFrame(tagsRDD).cache()\n",
    "\n",
    "lines = spark.read.text(\"ml-25m/tags.csv\").rdd\n",
    "parts = lines.map(lambda row: row.value.split(\",\"))\n",
    "header = parts.first()\n",
    "parts = parts.filter(lambda line: line != header)\n",
    "\n",
    "count_tagsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),tag=str(p[2]), timestamp=str(p[3])))\n",
    "count_tags = spark.createDataFrame(count_tagsRDD).cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fold_0, fold_1, fold_2) = ratings.randomSplit([1.0, 1.0, 1.0],seed=1234)\n",
    "\n",
    "data_list = [fold_0,fold_1,fold_2]\n",
    "test_list = [fold_2,fold_0,fold_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "als = ALS(maxIter=10, regParam=0.1, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(als_version):\n",
    "    dfItemFactors_list = []\n",
    "    fold_j = 0\n",
    "    for fold_i in range(len(data_list)):\n",
    "        if fold_j < len(data_list)-1:\n",
    "            fold_j+= 1\n",
    "        else:\n",
    "            fold_j = 0\n",
    "        first_train = data_list[fold_i].union(data_list[fold_j])\n",
    "        model = als_version.fit(first_train)\n",
    "        dfItemFactors=model.itemFactors\n",
    "        dfItemFactors_list.append(dfItemFactors)\n",
    "    return dfItemFactors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ItemFactors_list = cross_validate(als)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "def transData(data):\n",
    "    return data.rdd.map(lambda r: [r[0],Vectors.dense(r[1])]).toDF(['movieId','features'])\n",
    "                                                                   \n",
    "df_1_vec= transData(ItemFactors_list[0])\n",
    "df_2_vec= transData(ItemFactors_list[1])\n",
    "df_3_vec= transData(ItemFactors_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.clustering import KMeansModel\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "kmeans = KMeans().setK(25).setSeed(1234)\n",
    "model_1= kmeans.fit(df_1_vec)\n",
    "model_2= kmeans.fit(df_2_vec)\n",
    "model_3= kmeans.fit(df_3_vec)\n",
    "predictions_1 = model_1.transform(df_1_vec)\n",
    "predictions_2 = model_2.transform(df_2_vec)\n",
    "predictions_3 = model_3.transform(df_3_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieid_cluster_1 = predictions_1.drop('features')\n",
    "movieid_cluster_2 = predictions_2.drop('features')\n",
    "movieid_cluster_3 = predictions_3.drop('features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "largest_cluster_1 = predictions_1.groupBy('prediction').count().sort('count', ascending=False).limit(3)\n",
    "largest_cluster_2 = predictions_2.groupBy('prediction').count().sort('count', ascending=False).limit(3)\n",
    "largest_cluster_3 = predictions_3.groupBy('prediction').count().sort('count', ascending=False).limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Split:\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|        23| 4291|\n",
      "|        17| 4063|\n",
      "|        18| 3624|\n",
      "+----------+-----+\n",
      "\n",
      "Second Split:\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         0| 4691|\n",
      "|        17| 4029|\n",
      "|         5| 3512|\n",
      "+----------+-----+\n",
      "\n",
      "Third Split:\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         8| 3882|\n",
      "|        18| 3605|\n",
      "|         1| 3471|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"First Split:\")\n",
    "largest_cluster_1.show()\n",
    "print(\"Second Split:\")\n",
    "largest_cluster_2.show()\n",
    "print(\"Third Split:\")\n",
    "largest_cluster_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting dataset \n",
    "first_cluster_1 = movieid_cluster_1.filter(movieid_cluster_1['prediction'].contains(str(largest_cluster_1.collect()[0][0])))\n",
    "second_cluster_1 = movieid_cluster_1.filter(movieid_cluster_1['prediction'].contains(str(largest_cluster_1.collect()[1][0])))\n",
    "third_cluster_1 = movieid_cluster_1.filter(movieid_cluster_1['prediction'].contains(str(largest_cluster_1.collect()[2][0])))\n",
    "\n",
    "first_cluster_2 = movieid_cluster_2.filter(movieid_cluster_2['prediction'].contains(str(largest_cluster_2.collect()[0][0])))\n",
    "second_cluster_2 = movieid_cluster_2.filter(movieid_cluster_2['prediction'].contains(str(largest_cluster_2.collect()[1][0])))\n",
    "third_cluster_2 = movieid_cluster_2.filter(movieid_cluster_2['prediction'].contains(str(largest_cluster_2.collect()[2][0])))\n",
    "\n",
    "first_cluster_3 = movieid_cluster_3.filter(movieid_cluster_3['prediction'].contains(str(largest_cluster_3.collect()[0][0])))\n",
    "second_cluster_3 = movieid_cluster_3.filter(movieid_cluster_3['prediction'].contains(str(largest_cluster_3.collect()[1][0])))\n",
    "third_cluster_3 = movieid_cluster_3.filter(movieid_cluster_3['prediction'].contains(str(largest_cluster_3.collect()[2][0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use inner join to have all the tags for the movies in the cluster \n",
    "first_cluster_scores_1 = first_cluster_1.join(scores, on=['movieId'], how='inner')\n",
    "second_cluster_scores_1 = second_cluster_1.join(scores, on=['movieId'], how='inner')\n",
    "third_cluster_scores_1 = third_cluster_1.join(scores, on=['movieId'], how='inner')\n",
    "\n",
    "first_cluster_scores_2 = first_cluster_2.join(scores, on=['movieId'], how='inner')\n",
    "second_cluster_scores_2 = second_cluster_2.join(scores, on=['movieId'], how='inner')\n",
    "third_cluster_scores_2 = third_cluster_2.join(scores, on=['movieId'], how='inner')\n",
    "\n",
    "first_cluster_scores_3 = first_cluster_3.join(scores, on=['movieId'], how='inner')\n",
    "second_cluster_scores_3 = second_cluster_3.join(scores, on=['movieId'], how='inner')\n",
    "third_cluster_scores_3 = third_cluster_3.join(scores, on=['movieId'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the top 3 tags by adding all the scores, fc,sc,tc refer to first,second,third clusters.\n",
    "largest_tags_fc_1 = first_cluster_scores_1.groupBy('tagId').agg(func.sum('relevance'))\n",
    "largest_tags_fc_2 = second_cluster_scores_1.groupBy('tagId').agg(func.sum('relevance'))\n",
    "largest_tags_fc_3 = third_cluster_scores_1.groupBy('tagId').agg(func.sum('relevance'))\n",
    "\n",
    "largest_tags_sc_1 = first_cluster_scores_2.groupBy('tagId').agg(func.sum('relevance'))\n",
    "largest_tags_sc_2 = second_cluster_scores_2.groupBy('tagId').agg(func.sum('relevance'))\n",
    "largest_tags_sc_3 = third_cluster_scores_2.groupBy('tagId').agg(func.sum('relevance'))\n",
    "\n",
    "largest_tags_tc_1  = first_cluster_scores_3.groupBy('tagId').agg(func.sum('relevance'))\n",
    "largest_tags_tc_2 = second_cluster_scores_3.groupBy('tagId').agg(func.sum('relevance'))\n",
    "largest_tags_tc_3 = third_cluster_scores_3.groupBy('tagId').agg(func.sum('relevance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_fc_1 = largest_tags_fc_1.sort('sum(relevance)', ascending=False).limit(3)\n",
    "tags_fc_2 = largest_tags_fc_2.sort('sum(relevance)', ascending=False).limit(3)\n",
    "tags_fc_3 = largest_tags_fc_3.sort('sum(relevance)', ascending=False).limit(3)\n",
    "\n",
    "tags_sc_1 = largest_tags_sc_1.sort('sum(relevance)', ascending=False).limit(3)\n",
    "tags_sc_2 = largest_tags_sc_2.sort('sum(relevance)', ascending=False).limit(3)\n",
    "tags_sc_3 = largest_tags_sc_3.sort('sum(relevance)', ascending=False).limit(3)\n",
    "\n",
    "tags_tc_1 = largest_tags_tc_1.sort('sum(relevance)', ascending=False).limit(3)\n",
    "tags_tc_2 = largest_tags_tc_2.sort('sum(relevance)', ascending=False).limit(3)\n",
    "tags_tc_3 = largest_tags_tc_3.sort('sum(relevance)', ascending=False).limit(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------TOP 3 Tag for each cluster and split------------------------\n",
      "---------------------First Split First Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|mentor|  646|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 312\n",
      "+-------+-----+\n",
      "|    tag|tagId|\n",
      "+-------+-----+\n",
      "|runaway|  867|\n",
      "+-------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 87\n",
      "---------------------First Split Second Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|mentor|  646|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 312\n",
      "+------------+-----+\n",
      "|         tag|tagId|\n",
      "+------------+-----+\n",
      "|storytelling|  972|\n",
      "+------------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 464\n",
      "---------------------First Split Third Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|mentor|  646|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 312\n",
      "+-----+-----+\n",
      "|  tag|tagId|\n",
      "+-----+-----+\n",
      "|chase|  195|\n",
      "+-----+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 308\n",
      "---------------------Second Split First Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|mentor|  646|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 312\n",
      "+----+-----+\n",
      "| tag|tagId|\n",
      "+----+-----+\n",
      "|good|  445|\n",
      "+----+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 60\n",
      "---------------------Second Split Second Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|mentor|  646|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 312\n",
      "+-------+-----+\n",
      "|    tag|tagId|\n",
      "+-------+-----+\n",
      "|runaway|  867|\n",
      "+-------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 87\n",
      "---------------------Second Split Third Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|mentor|  646|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 312\n",
      "+-----------+-----+\n",
      "|        tag|tagId|\n",
      "+-----------+-----+\n",
      "|catastrophe|  188|\n",
      "+-----------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 108\n",
      "---------------------Third Split First Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+-----------+-----+\n",
      "|        tag|tagId|\n",
      "+-----------+-----+\n",
      "|predictable|  807|\n",
      "+-----------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 2278\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|mentor|  646|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 312\n",
      "---------------------Third Split Second Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|mentor|  646|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 312\n",
      "+-------------+-----+\n",
      "|          tag|tagId|\n",
      "+-------------+-----+\n",
      "|relationships|  846|\n",
      "+-------------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 839\n",
      "---------------------Third Split Third Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|mentor|  646|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 312\n",
      "+-------+-----+\n",
      "|    tag|tagId|\n",
      "+-------+-----+\n",
      "|runaway|  867|\n",
      "+-------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 87\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------TOP 3 Tag for each cluster and split------------------------\")\n",
    "print(\"---------------------First Split First Cluster------------------------\")\n",
    "tag_1 = tags.filter(tags['tagId']== tags_fc_1.collect()[0][0])\n",
    "tag_1.show()\n",
    "tag_1_count = count_tags.filter(count_tags['tag']==tag_1.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_1_count)\n",
    "\n",
    "tag_2 = tags.filter(tags['tagId']== tags_fc_1.collect()[1][0])\n",
    "tag_2.show()\n",
    "tag_2_count = count_tags.filter(count_tags['tag']==tag_2.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_2_count)\n",
    "\n",
    "tag_3 = tags.filter(tags['tagId']== tags_fc_1.collect()[2][0])\n",
    "tag_3.show()\n",
    "tag_3_count = count_tags.filter(count_tags['tag']==tag_3.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_3_count)\n",
    "\n",
    "print(\"---------------------First Split Second Cluster------------------------\")\n",
    "tag_4 = tags.filter(tags['tagId']== tags_sc_1.collect()[0][0])\n",
    "tag_4.show()\n",
    "tag_4_count = count_tags.filter(count_tags['tag']==tag_4.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_4_count)\n",
    "\n",
    "tag_5 = tags.filter(tags['tagId']== tags_sc_1.collect()[1][0])\n",
    "tag_5.show()\n",
    "tag_5_count = count_tags.filter(count_tags['tag']==tag_5.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_5_count)\n",
    "\n",
    "tag_6 = tags.filter(tags['tagId']== tags_sc_1.collect()[2][0])\n",
    "tag_6.show()\n",
    "tag_6_count = count_tags.filter(count_tags['tag']==tag_6.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_6_count)\n",
    "\n",
    "print(\"---------------------First Split Third Cluster------------------------\")\n",
    "tag_7 = tags.filter(tags['tagId']== tags_tc_1.collect()[0][0])\n",
    "tag_7.show()\n",
    "tag_7_count = count_tags.filter(count_tags['tag']==tag_7.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_7_count)\n",
    "\n",
    "tag_8 = tags.filter(tags['tagId']== tags_tc_1.collect()[1][0])\n",
    "tag_8.show()\n",
    "tag_8_count = count_tags.filter(count_tags['tag']==tag_8.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_8_count)\n",
    "\n",
    "tag_9 = tags.filter(tags['tagId']== tags_tc_1.collect()[2][0])\n",
    "tag_9.show()\n",
    "tag_9_count = count_tags.filter(count_tags['tag']==tag_9.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_9_count)\n",
    "\n",
    "print(\"---------------------Second Split First Cluster------------------------\")\n",
    "tag_10 = tags.filter(tags['tagId']== tags_fc_2.collect()[0][0])\n",
    "tag_10.show()\n",
    "tag_10_count = count_tags.filter(count_tags['tag']==tag_10.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_10_count)\n",
    "\n",
    "tag_11 = tags.filter(tags['tagId']== tags_fc_2.collect()[1][0])\n",
    "tag_11.show()\n",
    "tag_11_count = count_tags.filter(count_tags['tag']==tag_11.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_11_count)\n",
    "\n",
    "tag_12 = tags.filter(tags['tagId']== tags_fc_2.collect()[2][0])\n",
    "tag_12.show()\n",
    "tag_12_count = count_tags.filter(count_tags['tag']==tag_12.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_12_count)\n",
    "\n",
    "print(\"---------------------Second Split Second Cluster------------------------\")\n",
    "tag_13 = tags.filter(tags['tagId']== tags_sc_2.collect()[0][0])\n",
    "tag_13.show()\n",
    "tag_13_count = count_tags.filter(count_tags['tag']==tag_13.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_13_count)\n",
    "\n",
    "tag_14 = tags.filter(tags['tagId']== tags_sc_2.collect()[1][0])\n",
    "tag_14.show()\n",
    "tag_14_count = count_tags.filter(count_tags['tag']==tag_14.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_14_count)\n",
    "\n",
    "tag_15 = tags.filter(tags['tagId']== tags_sc_2.collect()[2][0])\n",
    "tag_15.show()\n",
    "tag_15_count = count_tags.filter(count_tags['tag']==tag_15.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_15_count)\n",
    "\n",
    "print(\"---------------------Second Split Third Cluster------------------------\")\n",
    "tag_16 = tags.filter(tags['tagId']== tags_tc_2.collect()[0][0])\n",
    "tag_16.show()\n",
    "tag_16_count = count_tags.filter(count_tags['tag']==tag_16.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_16_count)\n",
    "\n",
    "tag_17 = tags.filter(tags['tagId']== tags_tc_2.collect()[1][0])\n",
    "tag_17.show()\n",
    "tag_17_count = count_tags.filter(count_tags['tag']==tag_17.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_17_count)\n",
    "\n",
    "tag_18 = tags.filter(tags['tagId']== tags_tc_2.collect()[2][0])\n",
    "tag_18.show()\n",
    "tag_18_count = count_tags.filter(count_tags['tag']==tag_18.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_18_count)\n",
    "\n",
    "print(\"---------------------Third Split First Cluster------------------------\")\n",
    "tag_19 = tags.filter(tags['tagId']== tags_fc_3.collect()[0][0])\n",
    "tag_19.show()\n",
    "tag_19_count = count_tags.filter(count_tags['tag']==tag_19.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_19_count)\n",
    "\n",
    "tag_20 = tags.filter(tags['tagId']== tags_fc_3.collect()[1][0])\n",
    "tag_20.show()\n",
    "tag_20_count = count_tags.filter(count_tags['tag']==tag_20.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_20_count)\n",
    "\n",
    "tag_21 = tags.filter(tags['tagId']== tags_fc_3.collect()[2][0])\n",
    "tag_21.show()\n",
    "tag_21_count = count_tags.filter(count_tags['tag']==tag_21.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_21_count)\n",
    "\n",
    "print(\"---------------------Third Split Second Cluster------------------------\")\n",
    "tag_22 = tags.filter(tags['tagId']== tags_sc_3.collect()[0][0])\n",
    "tag_22.show()\n",
    "tag_22_count = count_tags.filter(count_tags['tag']==tag_22.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_22_count)\n",
    "\n",
    "tag_23 = tags.filter(tags['tagId']== tags_sc_3.collect()[1][0])\n",
    "tag_23.show()\n",
    "tag_23_count = count_tags.filter(count_tags['tag']==tag_23.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_23_count)\n",
    "\n",
    "tag_24 = tags.filter(tags['tagId']== tags_sc_3.collect()[2][0])\n",
    "tag_24.show()\n",
    "tag_24_count = count_tags.filter(count_tags['tag']==tag_24.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_24_count)\n",
    "\n",
    "print(\"---------------------Third Split Third Cluster------------------------\")\n",
    "tag_25 = tags.filter(tags['tagId']== tags_tc_3.collect()[0][0])\n",
    "tag_25.show()\n",
    "tag_25_count = count_tags.filter(count_tags['tag']==tag_25.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_25_count)\n",
    "\n",
    "tag_26 = tags.filter(tags['tagId']== tags_tc_3.collect()[1][0])\n",
    "tag_26.show()\n",
    "tag_26_count = count_tags.filter(count_tags['tag']==tag_26.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_26_count)\n",
    "\n",
    "tag_27 = tags.filter(tags['tagId']== tags_tc_3.collect()[2][0])\n",
    "tag_27.show()\n",
    "tag_27_count = count_tags.filter(count_tags['tag']==tag_27.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_27_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       original  mentor  runaway  original  mentor  storytelling  original  \\\n",
      "count      1077     312       87      1077     312           464      1077   \n",
      "\n",
      "       mentor  chase  original  ...  catastrophe  original  predictable  \\\n",
      "count     312    308      1077  ...          108      1077         2278   \n",
      "\n",
      "       mentor  original  mentor  relationships  original  mentor  runaway  \n",
      "count     312      1077     312            839      1077     312       87  \n",
      "\n",
      "[1 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "tag_report = sc.parallelize([(tag_1_count,tag_2_count,tag_3_count,\\\n",
    "                             tag_4_count,tag_5_count,tag_6_count,\\\n",
    "                            tag_7_count,tag_8_count,tag_9_count,\\\n",
    "                             tag_10_count,tag_11_count,tag_12_count,\\\n",
    "                            tag_13_count,tag_14_count,tag_15_count,\\\n",
    "                             tag_16_count,tag_17_count,tag_18_count,\\\n",
    "                            tag_19_count,tag_20_count,tag_21_count,\\\n",
    "                             tag_22_count,tag_23_count,tag_24_count,\\\n",
    "                            tag_25_count,tag_26_count,tag_27_count)])\n",
    "df_tag_report = tag_report.toDF([tag_1.collect()[0][0],tag_2.collect()[0][0],tag_3.collect()[0][0],tag_4.collect()[0][0],tag_5.collect()[0][0],tag_6.collect()[0][0],\\\n",
    "                            tag_7.collect()[0][0],tag_8.collect()[0][0],tag_9.collect()[0][0],tag_10.collect()[0][0],tag_11.collect()[0][0],tag_12.collect()[0][0],\\\n",
    "                            tag_13.collect()[0][0],tag_14.collect()[0][0],tag_15.collect()[0][0],tag_16.collect()[0][0],tag_17.collect()[0][0],tag_18.collect()[0][0],\\\n",
    "                            tag_19.collect()[0][0],tag_20.collect()[0][0],tag_21.collect()[0][0],tag_22.collect()[0][0],tag_23.collect()[0][0],tag_24.collect()[0][0],\\\n",
    "                            tag_25.collect()[0][0],tag_26.collect()[0][0],tag_27.collect()[0][0]])\n",
    "\n",
    "\n",
    "df_tag_report_pd = df_tag_report.toPandas()\n",
    "df_tag_report_pd.index = ['count']\n",
    "df_tag_report_pd.to_csv('tags_count')\n",
    "print(df_tag_report_pd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
