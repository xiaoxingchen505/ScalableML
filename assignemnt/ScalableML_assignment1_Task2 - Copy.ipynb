{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import findspark\n",
    "#findspark.init()\n",
    "import pyspark\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"COM6012 Assignment 1 Task2\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sc.setCheckpointDir('checkpoint/')\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    lines = spark.read.text(filepath).rdd\n",
    "    parts = lines.map(lambda row: row.value.split(\",\"))\n",
    "    header = parts.first()\n",
    "    parts = parts.filter(lambda line: line != header)\n",
    "    return parts\n",
    "\n",
    "ratingsRDD = load_data(\"small_data/ratings.csv\").map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),rating=float(p[2]), timestamp=str(p[3])))\n",
    "ratings = spark.createDataFrame(ratingsRDD).cache()\n",
    "\n",
    "scoresRDD = load_data(\"small_data/genome-scores.csv\").map(lambda p: Row(movieId=int(p[0]), tagId=int(p[1]),relevance=float(p[2])))\n",
    "scores = spark.createDataFrame(scoresRDD).cache()\n",
    "\n",
    "tagsRDD = load_data(\"small_data/genome-tags.csv\").map(lambda p: Row(tagId=int(p[0]), tag=str(p[1])))\n",
    "tags = spark.createDataFrame(tagsRDD).cache()\n",
    "\n",
    "count_tagsRDD = load_data(\"small_data/tags.csv\").map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),tag=str(p[2]), timestamp=str(p[3])))\n",
    "count_tags = spark.createDataFrame(count_tagsRDD).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fold_0, fold_1, fold_2) = ratings.randomSplit([1.0, 1.0, 1.0],seed=1234)\n",
    "\n",
    "data_list = [fold_0,fold_1,fold_2]\n",
    "test_list = [fold_2,fold_0,fold_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_1 = ALS(rank=10,maxIter=10, regParam=0.1, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "als_2 = ALS(rank=25, maxIter=50, regParam=0.05, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "als_3 = ALS(rank=50,maxIter=100, regParam=0.005, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "mae_evaluator = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\",predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(als_version, req_itemFactor= False):\n",
    "    \n",
    "    if req_itemFactor == True:\n",
    "        dfItemFactors_list = []\n",
    "        \n",
    "    rmse_list =[]\n",
    "    mae_list =[]\n",
    "    fold_j = 0\n",
    "    for fold_i in range(len(data_list)):\n",
    "        if fold_j < len(data_list)-1:\n",
    "            fold_j+= 1\n",
    "        else:\n",
    "            fold_j = 0\n",
    "        first_train = data_list[fold_i].union(data_list[fold_j])\n",
    "        model = als_version.fit(first_train)\n",
    "        predictions = model.transform(test_list[fold_i])\n",
    "        \n",
    "        rmse = rmse_evaluator.evaluate(predictions)\n",
    "        mae = mae_evaluator.evaluate(predictions)\n",
    "        rmse_list.append(rmse)\n",
    "        mae_list.append(mae)\n",
    "        \n",
    "        if req_itemFactor == True:\n",
    "            dfItemFactors=model.itemFactors\n",
    "            dfItemFactors_list.append(dfItemFactors)\n",
    "            \n",
    "    if req_itemFactor == True:\n",
    "        return dfItemFactors_list,rmse_list, mae_list\n",
    "    else:\n",
    "        return rmse_list, mae_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ItemFactors_list, rmse_als_1, mae_als_1 = cross_validate(als_1, req_itemFactor= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_als_2, mae_als_2 = cross_validate(als_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_als_3, mae_als_3 = cross_validate(als_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for calculate std and mean for rmse metric\n",
    "als1_rmse_std,als1_rmse_mean = stat.stdev(rmse_als_1),stat.mean(rmse_als_1)\n",
    "als2_rmse_std,als2_rmse_mean = stat.stdev(rmse_als_2),stat.mean(rmse_als_2)\n",
    "als3_rmse_std,als3_rmse_mean = stat.stdev(rmse_als_3),stat.mean(rmse_als_3)\n",
    "\n",
    "#for calculate std and mean for mae metric\n",
    "als1_mae_std,als1_mae_mean = stat.stdev(mae_als_1),stat.mean(mae_als_1)\n",
    "als2_mae_std,als2_mae_mean = stat.stdev(mae_als_2),stat.mean(mae_als_2)\n",
    "als3_mae_std,als3_mae_mean = stat.stdev(mae_als_3),stat.mean(mae_als_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_report = sc.parallelize([(rmse_als_1[0],mae_als_1[0],rmse_als_2[0],mae_als_2[0],rmse_als_3[0],mae_als_3[0]),\n",
    "                            (rmse_als_1[1],mae_als_1[1],rmse_als_2[1],mae_als_2[1],rmse_als_3[1],mae_als_3[1]),\n",
    "                            (rmse_als_1[2],mae_als_1[2],rmse_als_2[2],mae_als_2[2],rmse_als_3[2],mae_als_3[2]),\n",
    "                            (als1_rmse_std,als1_mae_std,als2_rmse_std,als2_mae_std,als3_rmse_std,als3_mae_std),\n",
    "                            (als1_rmse_mean,als1_mae_mean,als2_rmse_mean,als2_mae_mean,als3_rmse_mean,als3_mae_mean)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = rdd_report.toDF(['ALS Version 1 RMSE Result','ALS Version 1 MAE Result'\n",
    "                             ,'ALS Version 2 RMSE Result','ALS Version 2 MAE Result'\n",
    "                            ,'ALS Version 3 RMSE Result','ALS Version 3 MAE Result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = df_report.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd.index = ['Fold1','Fold2','Fold3','Std','Mean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ALS Version 1 RMSE Result  ALS Version 1 MAE Result  \\\n",
      "Fold1                   1.548004                  1.375677   \n",
      "Fold2                   2.020760                  1.826495   \n",
      "Fold3                   1.707850                  1.446223   \n",
      "Std                     0.240473                  0.242494   \n",
      "Mean                    1.758871                  1.549465   \n",
      "\n",
      "       ALS Version 2 RMSE Result  ALS Version 2 MAE Result  \\\n",
      "Fold1                   1.242028                  1.058165   \n",
      "Fold2                   1.514030                  1.339167   \n",
      "Fold3                   1.250609                  1.038737   \n",
      "Std                     0.154623                  0.168126   \n",
      "Mean                    1.335555                  1.145356   \n",
      "\n",
      "       ALS Version 3 RMSE Result  ALS Version 3 MAE Result  \n",
      "Fold1                   1.922107                  1.774399  \n",
      "Fold2                   2.297774                  2.160178  \n",
      "Fold3                   1.960509                  1.796914  \n",
      "Std                     0.206699                  0.216523  \n",
      "Mean                    2.060130                  1.910497  \n"
     ]
    }
   ],
   "source": [
    "print(df_pd)\n",
    "df_pd.to_csv('Q2A_result_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "def transData(data):\n",
    "    return data.rdd.map(lambda r: [r[0],Vectors.dense(r[1])]).toDF(['movieId','features'])\n",
    "                                                                   \n",
    "df_1_vec= transData(ItemFactors_list[0])\n",
    "df_2_vec= transData(ItemFactors_list[1])\n",
    "df_3_vec= transData(ItemFactors_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.clustering import KMeansModel\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "kmeans = KMeans().setK(25).setSeed(1234)\n",
    "model_1= kmeans.fit(df_1_vec)\n",
    "model_2= kmeans.fit(df_2_vec)\n",
    "model_3= kmeans.fit(df_3_vec)\n",
    "predictions_1 = model_1.transform(df_1_vec)\n",
    "predictions_2 = model_2.transform(df_2_vec)\n",
    "predictions_3 = model_3.transform(df_3_vec)\n",
    "\n",
    "movieid_cluster_1 = predictions_1.drop('features')\n",
    "movieid_cluster_2 = predictions_2.drop('features')\n",
    "movieid_cluster_3 = predictions_3.drop('features')\n",
    "\n",
    "largest_cluster_1 = predictions_1.groupBy('prediction').count().sort('count', ascending=False).limit(3)\n",
    "largest_cluster_2 = predictions_2.groupBy('prediction').count().sort('count', ascending=False).limit(3)\n",
    "largest_cluster_3 = predictions_3.groupBy('prediction').count().sort('count', ascending=False).limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Split:\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|        10|  168|\n",
      "|        12|  102|\n",
      "|         0|   89|\n",
      "+----------+-----+\n",
      "\n",
      "Second Split:\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         0|  178|\n",
      "|        11|   88|\n",
      "|        17|   68|\n",
      "+----------+-----+\n",
      "\n",
      "Third Split:\n",
      "+----------+-----+\n",
      "|prediction|count|\n",
      "+----------+-----+\n",
      "|         1|  178|\n",
      "|        10|   98|\n",
      "|        17|   75|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"First Split:\")\n",
    "largest_cluster_1.show()\n",
    "print(\"Second Split:\")\n",
    "largest_cluster_2.show()\n",
    "print(\"Third Split:\")\n",
    "largest_cluster_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting dataset \n",
    "first_cluster_1 = movieid_cluster_1.filter(movieid_cluster_1['prediction']== largest_cluster_1.collect()[0][0])\n",
    "second_cluster_1 = movieid_cluster_1.filter(movieid_cluster_1['prediction']== largest_cluster_1.collect()[1][0])\n",
    "third_cluster_1 = movieid_cluster_1.filter(movieid_cluster_1['prediction']== largest_cluster_1.collect()[2][0])\n",
    "\n",
    "first_cluster_2 = movieid_cluster_2.filter(movieid_cluster_2['prediction']==largest_cluster_2.collect()[0][0])\n",
    "second_cluster_2 = movieid_cluster_2.filter(movieid_cluster_2['prediction']==largest_cluster_2.collect()[1][0])\n",
    "third_cluster_2 = movieid_cluster_2.filter(movieid_cluster_2['prediction']==largest_cluster_2.collect()[2][0])\n",
    "\n",
    "first_cluster_3 = movieid_cluster_3.filter(movieid_cluster_3['prediction']==largest_cluster_3.collect()[0][0])\n",
    "second_cluster_3 = movieid_cluster_3.filter(movieid_cluster_3['prediction']==largest_cluster_3.collect()[1][0])\n",
    "third_cluster_3 = movieid_cluster_3.filter(movieid_cluster_3['prediction']==largest_cluster_3.collect()[2][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use inner join to have all the tags for the movies in the cluster \n",
    "first_cluster_scores_1 = first_cluster_1.join(scores, on=['movieId'], how='inner')\n",
    "second_cluster_scores_1 = second_cluster_1.join(scores, on=['movieId'], how='inner')\n",
    "third_cluster_scores_1 = third_cluster_1.join(scores, on=['movieId'], how='inner')\n",
    "\n",
    "first_cluster_scores_2 = first_cluster_2.join(scores, on=['movieId'], how='inner')\n",
    "second_cluster_scores_2 = second_cluster_2.join(scores, on=['movieId'], how='inner')\n",
    "third_cluster_scores_2 = third_cluster_2.join(scores, on=['movieId'], how='inner')\n",
    "\n",
    "first_cluster_scores_3 = first_cluster_3.join(scores, on=['movieId'], how='inner')\n",
    "second_cluster_scores_3 = second_cluster_3.join(scores, on=['movieId'], how='inner')\n",
    "third_cluster_scores_3 = third_cluster_3.join(scores, on=['movieId'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the top 3 tags by adding all the scores, fc,sc,tc refer to first,second,third clusters.\n",
    "largest_tags_fc_1 = first_cluster_scores_1.groupBy('tagId').agg(func.sum('relevance'))\n",
    "largest_tags_fc_2 = second_cluster_scores_1.groupBy('tagId').agg(func.sum('relevance'))\n",
    "largest_tags_fc_3 = third_cluster_scores_1.groupBy('tagId').agg(func.sum('relevance'))\n",
    "\n",
    "largest_tags_sc_1 = first_cluster_scores_2.groupBy('tagId').agg(func.sum('relevance'))\n",
    "largest_tags_sc_2 = second_cluster_scores_2.groupBy('tagId').agg(func.sum('relevance'))\n",
    "largest_tags_sc_3 = third_cluster_scores_2.groupBy('tagId').agg(func.sum('relevance'))\n",
    "\n",
    "largest_tags_tc_1  = first_cluster_scores_3.groupBy('tagId').agg(func.sum('relevance'))\n",
    "largest_tags_tc_2 = second_cluster_scores_3.groupBy('tagId').agg(func.sum('relevance'))\n",
    "largest_tags_tc_3 = third_cluster_scores_3.groupBy('tagId').agg(func.sum('relevance'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_fc_1 = largest_tags_fc_1.sort('sum(relevance)', ascending=False).limit(3)\n",
    "tags_fc_2 = largest_tags_fc_2.sort('sum(relevance)', ascending=False).limit(3)\n",
    "tags_fc_3 = largest_tags_fc_3.sort('sum(relevance)', ascending=False).limit(3)\n",
    "\n",
    "tags_sc_1 = largest_tags_sc_1.sort('sum(relevance)', ascending=False).limit(3)\n",
    "tags_sc_2 = largest_tags_sc_2.sort('sum(relevance)', ascending=False).limit(3)\n",
    "tags_sc_3 = largest_tags_sc_3.sort('sum(relevance)', ascending=False).limit(3)\n",
    "\n",
    "tags_tc_1 = largest_tags_tc_1.sort('sum(relevance)', ascending=False).limit(3)\n",
    "tags_tc_2 = largest_tags_tc_2.sort('sum(relevance)', ascending=False).limit(3)\n",
    "tags_tc_3 = largest_tags_tc_3.sort('sum(relevance)', ascending=False).limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|tagId|sum(relevance)    |\n",
      "+-----+------------------+\n",
      "|742  |133.76950000000002|\n",
      "|972  |111.48049999999996|\n",
      "|646  |110.35075000000002|\n",
      "+-----+------------------+\n",
      "\n",
      "+-----+-----------------+\n",
      "|tagId|sum(relevance)   |\n",
      "+-----+-----------------+\n",
      "|742  |74.78425000000001|\n",
      "|19   |70.47100000000005|\n",
      "|777  |70.17425000000003|\n",
      "+-----+-----------------+\n",
      "\n",
      "+-----+------------------+\n",
      "|tagId|sum(relevance)    |\n",
      "+-----+------------------+\n",
      "|742  |64.83599999999997 |\n",
      "|777  |55.433500000000016|\n",
      "|19   |53.385999999999996|\n",
      "+-----+------------------+\n",
      "\n",
      "+-----+------------------+\n",
      "|tagId|sum(relevance)    |\n",
      "+-----+------------------+\n",
      "|742  |143.06225         |\n",
      "|972  |117.99324999999997|\n",
      "|646  |115.77699999999993|\n",
      "+-----+------------------+\n",
      "\n",
      "+-----+------------------+\n",
      "|tagId|sum(relevance)    |\n",
      "+-----+------------------+\n",
      "|742  |63.67724999999999 |\n",
      "|19   |61.477749999999986|\n",
      "|777  |60.64925000000001 |\n",
      "+-----+------------------+\n",
      "\n",
      "+-----+------------------+\n",
      "|tagId|sum(relevance)    |\n",
      "+-----+------------------+\n",
      "|742  |49.777249999999974|\n",
      "|777  |44.087750000000014|\n",
      "|19   |41.5185           |\n",
      "+-----+------------------+\n",
      "\n",
      "+-----+------------------+\n",
      "|tagId|sum(relevance)    |\n",
      "+-----+------------------+\n",
      "|742  |142.50424999999996|\n",
      "|1091 |119.24099999999996|\n",
      "|972  |118.44299999999994|\n",
      "+-----+------------------+\n",
      "\n",
      "+-----+-----------------+\n",
      "|tagId|sum(relevance)   |\n",
      "+-----+-----------------+\n",
      "|742  |71.852           |\n",
      "|777  |64.95375000000003|\n",
      "|19   |64.57275000000001|\n",
      "+-----+-----------------+\n",
      "\n",
      "+-----+------------------+\n",
      "|tagId|sum(relevance)    |\n",
      "+-----+------------------+\n",
      "|742  |54.303749999999994|\n",
      "|19   |48.431750000000015|\n",
      "|777  |48.26875000000001 |\n",
      "+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tags_fc_1.show(5,False)\n",
    "tags_fc_2.show(5,False)\n",
    "tags_fc_3.show(5,False)\n",
    "tags_sc_1.show(5,False)\n",
    "tags_sc_2.show(5,False)\n",
    "tags_sc_3.show(5,False)\n",
    "tags_tc_1.show(5,False)\n",
    "tags_tc_2.show(5,False)\n",
    "tags_tc_3.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------TOP 3 Tag for each cluster and split------------------------\n",
      "---------------------First Split First Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+------------+-----+\n",
      "|         tag|tagId|\n",
      "+------------+-----+\n",
      "|storytelling|  972|\n",
      "+------------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 464\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|mentor|  646|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 312\n",
      "---------------------First Split Second Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+------------+-----+\n",
      "|         tag|tagId|\n",
      "+------------+-----+\n",
      "|storytelling|  972|\n",
      "+------------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 464\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|mentor|  646|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 312\n",
      "---------------------First Split Third Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|mentor|  646|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 312\n",
      "+-----+-----+\n",
      "|  tag|tagId|\n",
      "+-----+-----+\n",
      "|pg-13|  777|\n",
      "+-----+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 2\n",
      "---------------------Second Split First Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|action|   19|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 5907\n",
      "+-----+-----+\n",
      "|  tag|tagId|\n",
      "+-----+-----+\n",
      "|pg-13|  777|\n",
      "+-----+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 2\n",
      "---------------------Second Split Second Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|action|   19|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 5907\n",
      "+-----+-----+\n",
      "|  tag|tagId|\n",
      "+-----+-----+\n",
      "|pg-13|  777|\n",
      "+-----+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 2\n",
      "---------------------Second Split Third Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+-----+-----+\n",
      "|  tag|tagId|\n",
      "+-----+-----+\n",
      "|pg-13|  777|\n",
      "+-----+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 2\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|action|   19|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 5907\n",
      "---------------------Third Split First Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+-----+-----+\n",
      "|  tag|tagId|\n",
      "+-----+-----+\n",
      "|pg-13|  777|\n",
      "+-----+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 2\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|mentor|  646|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 312\n",
      "---------------------Third Split Second Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+-----+-----+\n",
      "|  tag|tagId|\n",
      "+-----+-----+\n",
      "|pg-13|  777|\n",
      "+-----+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 2\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|action|   19|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 5907\n",
      "---------------------Third Split Third Cluster------------------------\n",
      "+--------+-----+\n",
      "|     tag|tagId|\n",
      "+--------+-----+\n",
      "|original|  742|\n",
      "+--------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 1077\n",
      "+------+-----+\n",
      "|   tag|tagId|\n",
      "+------+-----+\n",
      "|action|   19|\n",
      "+------+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 5907\n",
      "+-----+-----+\n",
      "|  tag|tagId|\n",
      "+-----+-----+\n",
      "|pg-13|  777|\n",
      "+-----+-----+\n",
      "\n",
      "Respective Number of movies having the tags: 2\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------TOP 3 Tag for each cluster and split------------------------\")\n",
    "print(\"---------------------First Split First Cluster------------------------\")\n",
    "tag_1 = tags.filter(tags['tagId']== tags_fc_1.collect()[0][0])\n",
    "tag_1.show()\n",
    "tag_1_count = count_tags.filter(count_tags['tag']==tag_1.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_1_count)\n",
    "\n",
    "tag_2 = tags.filter(tags['tagId']== tags_fc_1.collect()[1][0])\n",
    "tag_2.show()\n",
    "tag_2_count = count_tags.filter(count_tags['tag']==tag_2.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_2_count)\n",
    "\n",
    "tag_3 = tags.filter(tags['tagId']== tags_fc_1.collect()[2][0])\n",
    "tag_3.show()\n",
    "tag_3_count = count_tags.filter(count_tags['tag']==tag_3.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_3_count)\n",
    "\n",
    "print(\"---------------------First Split Second Cluster------------------------\")\n",
    "tag_4 = tags.filter(tags['tagId']== tags_sc_1.collect()[0][0])\n",
    "tag_4.show()\n",
    "tag_4_count = count_tags.filter(count_tags['tag']==tag_4.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_4_count)\n",
    "\n",
    "tag_5 = tags.filter(tags['tagId']== tags_sc_1.collect()[1][0])\n",
    "tag_5.show()\n",
    "tag_5_count = count_tags.filter(count_tags['tag']==tag_5.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_5_count)\n",
    "\n",
    "tag_6 = tags.filter(tags['tagId']== tags_sc_1.collect()[2][0])\n",
    "tag_6.show()\n",
    "tag_6_count = count_tags.filter(count_tags['tag']==tag_6.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_6_count)\n",
    "\n",
    "print(\"---------------------First Split Third Cluster------------------------\")\n",
    "tag_7 = tags.filter(tags['tagId']== tags_tc_1.collect()[0][0])\n",
    "tag_7.show()\n",
    "tag_7_count = count_tags.filter(count_tags['tag']==tag_7.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_7_count)\n",
    "\n",
    "tag_8 = tags.filter(tags['tagId']== tags_tc_1.collect()[1][0])\n",
    "tag_8.show()\n",
    "tag_8_count = count_tags.filter(count_tags['tag']==tag_8.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_8_count)\n",
    "\n",
    "tag_9 = tags.filter(tags['tagId']== tags_tc_1.collect()[2][0])\n",
    "tag_9.show()\n",
    "tag_9_count = count_tags.filter(count_tags['tag']==tag_9.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_9_count)\n",
    "\n",
    "print(\"---------------------Second Split First Cluster------------------------\")\n",
    "tag_10 = tags.filter(tags['tagId']== tags_fc_2.collect()[0][0])\n",
    "tag_10.show()\n",
    "tag_10_count = count_tags.filter(count_tags['tag']==tag_10.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_10_count)\n",
    "\n",
    "tag_11 = tags.filter(tags['tagId']== tags_fc_2.collect()[1][0])\n",
    "tag_11.show()\n",
    "tag_11_count = count_tags.filter(count_tags['tag']==tag_11.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_11_count)\n",
    "\n",
    "tag_12 = tags.filter(tags['tagId']== tags_fc_2.collect()[2][0])\n",
    "tag_12.show()\n",
    "tag_12_count = count_tags.filter(count_tags['tag']==tag_12.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_12_count)\n",
    "\n",
    "print(\"---------------------Second Split Second Cluster------------------------\")\n",
    "tag_13 = tags.filter(tags['tagId']== tags_sc_2.collect()[0][0])\n",
    "tag_13.show()\n",
    "tag_13_count = count_tags.filter(count_tags['tag']==tag_13.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_13_count)\n",
    "\n",
    "tag_14 = tags.filter(tags['tagId']== tags_sc_2.collect()[1][0])\n",
    "tag_14.show()\n",
    "tag_14_count = count_tags.filter(count_tags['tag']==tag_14.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_14_count)\n",
    "\n",
    "tag_15 = tags.filter(tags['tagId']== tags_sc_2.collect()[2][0])\n",
    "tag_15.show()\n",
    "tag_15_count = count_tags.filter(count_tags['tag']==tag_15.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_15_count)\n",
    "\n",
    "print(\"---------------------Second Split Third Cluster------------------------\")\n",
    "tag_16 = tags.filter(tags['tagId']== tags_tc_2.collect()[0][0])\n",
    "tag_16.show()\n",
    "tag_16_count = count_tags.filter(count_tags['tag']==tag_16.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_16_count)\n",
    "\n",
    "tag_17 = tags.filter(tags['tagId']== tags_tc_2.collect()[1][0])\n",
    "tag_17.show()\n",
    "tag_17_count = count_tags.filter(count_tags['tag']==tag_17.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_17_count)\n",
    "\n",
    "tag_18 = tags.filter(tags['tagId']== tags_tc_2.collect()[2][0])\n",
    "tag_18.show()\n",
    "tag_18_count = count_tags.filter(count_tags['tag']==tag_18.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_18_count)\n",
    "\n",
    "print(\"---------------------Third Split First Cluster------------------------\")\n",
    "tag_19 = tags.filter(tags['tagId']== tags_fc_3.collect()[0][0])\n",
    "tag_19.show()\n",
    "tag_19_count = count_tags.filter(count_tags['tag']==tag_19.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_19_count)\n",
    "\n",
    "tag_20 = tags.filter(tags['tagId']== tags_fc_3.collect()[1][0])\n",
    "tag_20.show()\n",
    "tag_20_count = count_tags.filter(count_tags['tag']==tag_20.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_20_count)\n",
    "\n",
    "tag_21 = tags.filter(tags['tagId']== tags_fc_3.collect()[2][0])\n",
    "tag_21.show()\n",
    "tag_21_count = count_tags.filter(count_tags['tag']==tag_21.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_21_count)\n",
    "\n",
    "print(\"---------------------Third Split Second Cluster------------------------\")\n",
    "tag_22 = tags.filter(tags['tagId']== tags_sc_3.collect()[0][0])\n",
    "tag_22.show()\n",
    "tag_22_count = count_tags.filter(count_tags['tag']==tag_22.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_22_count)\n",
    "\n",
    "tag_23 = tags.filter(tags['tagId']== tags_sc_3.collect()[1][0])\n",
    "tag_23.show()\n",
    "tag_23_count = count_tags.filter(count_tags['tag']==tag_23.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_23_count)\n",
    "\n",
    "tag_24 = tags.filter(tags['tagId']== tags_sc_3.collect()[2][0])\n",
    "tag_24.show()\n",
    "tag_24_count = count_tags.filter(count_tags['tag']==tag_24.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_24_count)\n",
    "\n",
    "print(\"---------------------Third Split Third Cluster------------------------\")\n",
    "tag_25 = tags.filter(tags['tagId']== tags_tc_3.collect()[0][0])\n",
    "tag_25.show()\n",
    "tag_25_count = count_tags.filter(count_tags['tag']==tag_25.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_25_count)\n",
    "\n",
    "tag_26 = tags.filter(tags['tagId']== tags_tc_3.collect()[1][0])\n",
    "tag_26.show()\n",
    "tag_26_count = count_tags.filter(count_tags['tag']==tag_26.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_26_count)\n",
    "\n",
    "tag_27 = tags.filter(tags['tagId']== tags_tc_3.collect()[2][0])\n",
    "tag_27.show()\n",
    "tag_27_count = count_tags.filter(count_tags['tag']==tag_27.collect()[0][0]).count()\n",
    "print('Respective Number of movies having the tags:',tag_27_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       original  storytelling  mentor  original  storytelling  mentor  \\\n",
      "count      1077           464     312      1077           464     312   \n",
      "\n",
      "       original  mentor  pg-13  original  ...  action  original  pg-13  \\\n",
      "count      1077     312      2      1077  ...    5907      1077      2   \n",
      "\n",
      "       mentor  original  pg-13  action  original  action  pg-13  \n",
      "count     312      1077      2    5907      1077    5907      2  \n",
      "\n",
      "[1 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "tag_report = sc.parallelize([(tag_1_count,tag_2_count,tag_3_count,\\\n",
    "                             tag_4_count,tag_5_count,tag_6_count,\\\n",
    "                            tag_7_count,tag_8_count,tag_9_count,\\\n",
    "                             tag_10_count,tag_11_count,tag_12_count,\\\n",
    "                            tag_13_count,tag_14_count,tag_15_count,\\\n",
    "                             tag_16_count,tag_17_count,tag_18_count,\\\n",
    "                            tag_19_count,tag_20_count,tag_21_count,\\\n",
    "                             tag_22_count,tag_23_count,tag_24_count,\\\n",
    "                            tag_25_count,tag_26_count,tag_27_count)])\n",
    "df_tag_report = tag_report.toDF([tag_1.collect()[0][0],tag_2.collect()[0][0],tag_3.collect()[0][0],tag_4.collect()[0][0],tag_5.collect()[0][0],tag_6.collect()[0][0],\\\n",
    "                            tag_7.collect()[0][0],tag_8.collect()[0][0],tag_9.collect()[0][0],tag_10.collect()[0][0],tag_11.collect()[0][0],tag_12.collect()[0][0],\\\n",
    "                            tag_13.collect()[0][0],tag_14.collect()[0][0],tag_15.collect()[0][0],tag_16.collect()[0][0],tag_17.collect()[0][0],tag_18.collect()[0][0],\\\n",
    "                            tag_19.collect()[0][0],tag_20.collect()[0][0],tag_21.collect()[0][0],tag_22.collect()[0][0],tag_23.collect()[0][0],tag_24.collect()[0][0],\\\n",
    "                            tag_25.collect()[0][0],tag_26.collect()[0][0],tag_27.collect()[0][0]])\n",
    "\n",
    "\n",
    "df_tag_report_pd = df_tag_report.toPandas()\n",
    "df_tag_report_pd.index = ['count']\n",
    "print(df_tag_report_pd)\n",
    "df_tag_report_pd.to_csv('tags_count_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
