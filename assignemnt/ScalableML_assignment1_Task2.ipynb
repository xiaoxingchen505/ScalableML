{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import findspark\n",
    "#findspark.init()\n",
    "import pyspark\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "import pyspark.sql.functions as func\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"COM6012 Assignment 1 Task2\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\")\\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sc.setCheckpointDir('checkpoint/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = spark.read.text(\"ml-25m/ratings.csv\").rdd\n",
    "parts = lines.map(lambda row: row.value.split(\",\"))\n",
    "\n",
    "header = parts.first()\n",
    "parts = parts.filter(lambda line: line != header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsRDD = parts.map(lambda p: Row(userId=int(p[0]), movieId=int(p[1]),rating=float(p[2]), timestamp=int(p[3])))\n",
    "ratings = spark.createDataFrame(ratingsRDD).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(fold_0, fold_1, fold_2) = ratings.randomSplit([1.0, 1.0, 1.0])\n",
    "\n",
    "data_list = [fold_0,fold_1,fold_2]\n",
    "test_list = [fold_2,fold_0,fold_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "als_1 = ALS(rank=10,maxIter=10, regParam=0.1, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "als_2 = ALS(rank=25, maxIter=50, regParam=0.05, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "als_3 = ALS(rank=50,maxIter=100, regParam=0.005, userCol=\"userId\", itemCol=\"movieId\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\",predictionCol=\"prediction\")\n",
    "mae_evaluator = RegressionEvaluator(metricName=\"mae\", labelCol=\"rating\",predictionCol=\"prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(als_version):\n",
    "    rmse_list =[]\n",
    "    mae_list =[]\n",
    "    fold_j = 0\n",
    "    for fold_i in range(len(data_list)):\n",
    "        if fold_j < len(data_list)-1:\n",
    "            fold_j+= 1\n",
    "        else:\n",
    "            fold_j = 0\n",
    "        first_train = data_list[fold_i].union(data_list[fold_j])\n",
    "        model = als_version.fit(first_train)\n",
    "        predictions = model.transform(test_list[fold_i])\n",
    "        \n",
    "        rmse = rmse_evaluator.evaluate(predictions)\n",
    "        mae = mae_evaluator.evaluate(predictions)\n",
    "        \n",
    "        rmse_list.append(rmse)\n",
    "        mae_list.append(mae)\n",
    "    \n",
    "    return rmse_list, mae_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_als_1, mae_als_1 = cross_validate(als_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_als_2, mae_als_2 = cross_validate(als_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_als_3, mae_als_3 = cross_validate(als_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for calculate std and mean for rmse metric\n",
    "als1_rmse_std,als1_rmse_mean = stat.stdev(rmse_als_1),stat.mean(rmse_als_1)\n",
    "als2_rmse_std,als2_rmse_mean = stat.stdev(rmse_als_2),stat.mean(rmse_als_2)\n",
    "als3_rmse_std,als3_rmse_mean = stat.stdev(rmse_als_3),stat.mean(rmse_als_3)\n",
    "\n",
    "#for calculate std and mean for mae metric\n",
    "als1_mae_std,als1_mae_mean = stat.stdev(mae_als_1),stat.mean(mae_als_1)\n",
    "als2_mae_std,als2_mae_mean = stat.stdev(mae_als_2),stat.mean(mae_als_2)\n",
    "als3_mae_std,als3_mae_mean = stat.stdev(mae_als_3),stat.mean(mae_als_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_report = sc.parallelize([(rmse_als_1[0],mae_als_1[0],rmse_als_2[0],mae_als_2[0],rmse_als_3[0],mae_als_3[0]),\n",
    "                            (rmse_als_1[1],mae_als_1[1],rmse_als_2[1],mae_als_2[1],rmse_als_3[1],mae_als_3[1]),\n",
    "                            (rmse_als_1[2],mae_als_1[2],rmse_als_2[2],mae_als_2[2],rmse_als_3[2],mae_als_3[2]),\n",
    "                            (als1_rmse_std,als1_mae_std,als2_rmse_std,als2_mae_std,als3_rmse_std,als3_mae_std),\n",
    "                            (als1_rmse_mean,als1_mae_mean,als2_rmse_mean,als2_mae_mean,als3_rmse_mean,als3_mae_mean)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_report = rdd_report.toDF(['ALS Version 1 RMSE Result','ALS Version 1 MAE Result'\n",
    "                             ,'ALS Version 2 RMSE Result','ALS Version 2 MAE Result'\n",
    "                            ,'ALS Version 3 RMSE Result','ALS Version 3 MAE Result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = df_report.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd.index = ['Fold1','Fold2','Fold3','Std','Mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ALS Version 1 RMSE Result  ALS Version 1 MAE Result  \\\n",
      "Fold1                   0.807545                  0.624696   \n",
      "Fold2                   0.807281                  0.624130   \n",
      "Fold3                   0.807356                  0.624287   \n",
      "Std                     0.000136                  0.000292   \n",
      "Mean                    0.807394                  0.624371   \n",
      "\n",
      "       ALS Version 2 RMSE Result  ALS Version 2 MAE Result  \\\n",
      "Fold1                   0.774679                  0.589901   \n",
      "Fold2                   0.774869                  0.589952   \n",
      "Fold3                   0.775069                  0.590149   \n",
      "Std                     0.000195                  0.000131   \n",
      "Mean                    0.774872                  0.590001   \n",
      "\n",
      "       ALS Version 3 RMSE Result  ALS Version 3 MAE Result  \n",
      "Fold1                   0.911161                  0.674686  \n",
      "Fold2                   0.911065                  0.674737  \n",
      "Fold3                   0.910310                  0.674324  \n",
      "Std                     0.000466                  0.000225  \n",
      "Mean                    0.910845                  0.674582  \n"
     ]
    }
   ],
   "source": [
    "print(df_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
