{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start data preprocessing...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row,Column\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"COM6012 Assignment Task2\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\")\\\n",
    "    .config(\"spark.executor.cores\", 8)\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"OFF\")\n",
    "\n",
    "#start Data pre-processing\n",
    "raw_df = spark.read.csv('./Dataset/ClaimPredictionChallenge/train_set.csv',header= True)\n",
    "\n",
    "raw_df = raw_df.sample(False,0.01,47)\n",
    "\n",
    "raw_df =raw_df.select('Vehicle','Var1','Var2','Var3','Var4','Var5','Var6','Var7','Var8','NVVar1','NVVar2','NVVar3','NVVar4',\n",
    "                  'Cat1','Cat2','Cat3','Cat4','Cat5','Cat6','Cat7','Cat8','Cat9','Cat10','Cat11','Cat12','Calendar_Year','Model_Year','Claim_Amount')\n",
    "\n",
    "print('')\n",
    "print('Start data preprocessing...')\n",
    "print('')\n",
    "for col in raw_df.columns:\n",
    "    raw_df = raw_df.filter((raw_df[col] != '?'))\n",
    "\n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "double_data = ['Var1','Var2','Var3','Var4','Var5','Var6','Var7','Var8','NVVar1','NVVar2','NVVar3','NVVar4']\n",
    "int_data = ['Vehicle','Calendar_Year','Model_Year','Claim_Amount']\n",
    "input_features = double_data+int_data\n",
    "for col in double_data:\n",
    "    raw_df = raw_df.withColumn(col, raw_df[col].cast(DoubleType()))\n",
    "for col in int_data:\n",
    "    raw_df = raw_df.withColumn(col, raw_df[col].cast(IntegerType()))\n",
    "\n",
    "raw_df = raw_df.withColumn(int_data[0], (raw_df[int_data[0]]-2005))\n",
    "raw_df = raw_df.withColumn(int_data[1], (raw_df[int_data[1]]-1981))\n",
    "\n",
    "#categorical Nbr Lvls in Train for each cat\n",
    "categorical_features = {'Cat1':11,'Cat2':4,'Cat3':7,'Cat4':4,'Cat5':4,'Cat6':7,'Cat7':5,'Cat8':4,'Cat9':2,'Cat10':4,'Cat11':7,'Cat12':7}\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer,OneHotEncoderEstimator\n",
    "\n",
    "for col,num in categorical_features.items():\n",
    "    name = col+'_id'\n",
    "    indexer = StringIndexer(inputCol=col, outputCol=name)\n",
    "    raw_df = indexer.fit(raw_df).transform(raw_df)\n",
    "\n",
    "raw_df = raw_df.select('Var1','Var2','Var3','Var4','Var5','Var6','Var7','Var8',\\\n",
    "                        'NVVar1','NVVar2','NVVar3','NVVar4',\\\n",
    "                        'Cat1_id','Cat2_id','Cat3_id','Cat4_id','Cat5_id','Cat6_id','Cat7_id','Cat8_id','Cat9_id','Cat10_id','Cat11_id','Cat12_id',\\\n",
    "                        'Calendar_Year','Model_Year','Claim_Amount')\n",
    "\n",
    "category_id = ['Cat1_id','Cat2_id','Cat3_id','Cat4_id','Cat5_id','Cat6_id','Cat7_id','Cat8_id','Cat9_id','Cat10_id','Cat11_id','Cat12_id']\n",
    "cat_ohe = []\n",
    "for col in category_id:\n",
    "    cat_ = col.replace('_id','_ohe')\n",
    "    cat_ohe.append(cat_)\n",
    "    input_features.append(cat_)\n",
    "\n",
    "\n",
    "data = raw_df.select('Var1','Var2','Var3','Var4','Var5','Var6','Var7','Var8','NVVar1','NVVar2','NVVar3','NVVar4',\n",
    "                  'Cat1_id','Cat2_id','Cat3_id','Cat4_id','Cat5_id','Cat6_id','Cat7_id','Cat8_id','Cat9_id','Cat10_id','Cat11_id','Cat12_id','Calendar_Year','Model_Year','Claim_Amount')\n",
    "\n",
    "encoder = OneHotEncoderEstimator(inputCols=category_id, outputCols=cat_ohe)\n",
    "\n",
    "encoder_data = encoder.fit(data)\n",
    "data_ohe = encoder_data.transform(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #assemble all features\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "all_features_assembler = VectorAssembler(inputCols=['Cat1_ohe','Cat2_ohe','Cat3_ohe','Cat4_ohe'\\\n",
    "                                                    ,'Cat5_ohe','Cat6_ohe','Cat7_ohe','Cat8_ohe'\\\n",
    "                                                    ,'Cat9_ohe','Cat10_ohe','Cat11_ohe','Cat12_ohe'\\\n",
    "                                                    ,'Var1','Var2','Var3','Var4','Var5',\\\n",
    "                                                        'Var6','Var7','Var8','NVVar1','NVVar2'\\\n",
    "                                                    ,'NVVar3','NVVar4','Calendar_Year','Model_Year'],\\\n",
    "                                                    outputCol='features')\n",
    "all_data = all_features_assembler.transform(data_ohe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start to train model\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import when\n",
    "\n",
    "t_data= all_data.select('features','Claim_Amount')\n",
    "(trainingData, testData) = t_data.randomSplit([0.7, 0.3], 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing finished.\n",
      "Start training......\n",
      "Execution time: 60.81381916999817\n",
      "RMSE = 32.2269\n",
      "MAE = 2.47114\n"
     ]
    }
   ],
   "source": [
    "trainingData.cache()  \n",
    "testData.cache()\n",
    "print('Data preprocessing finished.')\n",
    "\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Claim_Amount\")\n",
    "\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "print('Start training......')\n",
    "lr_Model = lr.fit(trainingData)\n",
    "\n",
    "lr_prediction = lr_Model.transform(testData)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Claim_Amount\",\\\n",
    "                                predictionCol=\"prediction\",\\\n",
    "                                metricName=\"rmse\")\n",
    "\n",
    "lr_rmse = evaluator.evaluate(lr_prediction)\n",
    "end = time.time()\n",
    "print('Execution time:',end-start)\n",
    "print(\"RMSE = %g\" % lr_rmse)\n",
    "evaluator = RegressionEvaluator(labelCol=\"Claim_Amount\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "lr_mae = evaluator.evaluate(lr_prediction)\n",
    "print(\"MAE = %g\" % lr_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE = 2.47114\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"Claim_Amount\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "lr_mae = evaluator.evaluate(lr_prediction)\n",
    "print(\"MAE = %g\" % lr_mae)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
