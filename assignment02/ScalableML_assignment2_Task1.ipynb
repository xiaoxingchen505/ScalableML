{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "spark = SparkSession.builder.master(\"local[2]\")\\\n",
    "                            .appName(\"COM6012 Assignment Question——1\")\\\n",
    "                            .config(\"spark.driver.memory\", \"8g\")\\\n",
    "                            .config(\"spark.executor.cores\", 8)\\\n",
    "                            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = spark.read.csv('.\\Dataset\\HIGGS.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['lepton pT', 'lepton eta', 'lepton phi', \n",
    "                 'missing energy magnitude', 'missing energy phi', \n",
    "                 'jet 1 pt', 'jet 1 eta', 'jet 1 phi', 'jet 1 b-tag', \n",
    "                 'jet 2 pt', 'jet 2 eta', 'jet 2 phi', 'jet 2 b-tag', \n",
    "                 'jet 3 pt', 'jet 3 eta', 'jet 3 phi', 'jet 3 b-tag', \n",
    "                 'jet 4 pt', 'jet 4 eta', 'jet 4 phi', 'jet 4 b-tag', \n",
    "                 'm_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_bb', 'm_wbb', 'm_wwbb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemaNames = rawdata.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncolumns = len(rawdata.columns)\n",
    "rawdata = rawdata.withColumnRenamed(schemaNames[0],'labels')\n",
    "for i in range(ncolumns-1):\n",
    "     rawdata = rawdata.withColumnRenamed(schemaNames[i+1], feature_names[i])\n",
    "schemaNames = rawdata.schema.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "for i in range(ncolumns):\n",
    "    rawdata = rawdata.withColumn(schemaNames[i], rawdata[schemaNames[i]].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols = schemaNames[1:ncolumns], outputCol = 'features') \n",
    "raw_plus_vector = assembler.transform(rawdata)\n",
    "data = raw_plus_vector.select('features','labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = data.sample(False, 0.0005,47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- features: vector (nullable = true)\n",
      " |-- labels: double (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[features: vector, labels: double]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_data.printSchema()\n",
    "small_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "rf = RandomForestClassifier(featuresCol=\"features\",labelCol=\"labels\")\n",
    "\n",
    "gbt = GBTClassifier(featuresCol=\"features\",labelCol=\"labels\")\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline_rf = Pipeline(stages=[rf])\n",
    "pipeline_gbt = Pipeline(stages=[gbt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#parameter grid for random forest \n",
    "paramGrid_rf = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [3, 5, 7]) \\\n",
    "    .addGrid(rf.maxDepth, [3, 5, 7]) \\\n",
    "    .addGrid(rf.maxBins, [3, 5, 7])\\\n",
    "    .build()\n",
    "\n",
    "#parameter grid for gradient boost \n",
    "paramGrid_gbt = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [2,4,6]) \\\n",
    "    .addGrid(gbt.maxDepth, [3, 5, 7]) \\\n",
    "    .addGrid(gbt.maxBins, [3, 5, 7])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest execution time: 307.8934078216553\n",
      "GBT execution time: 111.27849268913269\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import time\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labels\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "crossval_rf = CrossValidator(estimator=pipeline_rf,\n",
    "                          estimatorParamMaps=paramGrid_rf,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "crossval_gbt = CrossValidator(estimator=pipeline_gbt,\n",
    "                          estimatorParamMaps=paramGrid_gbt,\n",
    "                          evaluator=evaluator,\n",
    "                          numFolds=3)\n",
    "\n",
    "(trainingData, testData) = small_data.randomSplit([0.8, 0.2],47)\n",
    "\n",
    "start = time.time()\n",
    "rfModel = crossval_rf.fit(trainingData)\n",
    "rf_predictions = rfModel.transform(testData)\n",
    "end = time.time()\n",
    "print('Random Forest execution time:',end-start)\n",
    "\n",
    "start = time.time()\n",
    "gbtModel = crossval_gbt.fit(trainingData)\n",
    "gbt_predictions = gbtModel.transform(testData)\n",
    "end = time.time()\n",
    "print('GBT execution time:',end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Random Forest Score-----\n",
      "accuracy score: 0.6513513513513514\n",
      "AUC score: 0.7089434678314426\n",
      "                             \n",
      "--------GBT Score------------\n",
      "accuracy score: 0.6342342342342342\n",
      "AUC score: 0.6934946833267692\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labels\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "rf_accuracy_score = evaluator.evaluate(rf_predictions)\n",
    "\n",
    "gbt_accuracy_score = evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"labels\",rawPredictionCol='rawPrediction', metricName=\"areaUnderROC\")\n",
    "\n",
    "rf_auc_score = evaluator.evaluate(rf_predictions)\n",
    "\n",
    "gbt_auc_score = evaluator.evaluate(gbt_predictions)\n",
    "\n",
    "print('-----Random Forest Score-----')\n",
    "print('accuracy score:',rf_accuracy_score)\n",
    "print('AUC score:',rf_auc_score)\n",
    "print('                             ')\n",
    "print('--------GBT Score------------')\n",
    "print('accuracy score:',gbt_accuracy_score)\n",
    "print('AUC score:',gbt_auc_score)\n",
    "\n",
    "\n",
    "bestPipeline_rf, bestPipeline_gbt = rfModel.bestModel, gbtModel.bestModel\n",
    "\n",
    "bestModel_rf, bestModel_gbt = bestPipeline_rf.stages[0], bestPipeline_gbt.stages[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------Random Forest best model-----------\n",
      "numTrees -  7\n",
      "maxDepth -  7\n",
      "maxBins -  7\n",
      "------------------------------------------\n",
      "---------------GBT best model-------------\n",
      "maxIter -  6\n",
      "maxDepth -  3\n",
      "maxBins -  5\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('-------Random Forest best model-----------')\n",
    "print('numTrees - ', bestModel_rf.getNumTrees)\n",
    "print('maxDepth - ', bestModel_rf.getOrDefault('maxDepth'))\n",
    "print('maxBins - ', bestModel_rf.getOrDefault('maxBins'))\n",
    "print('------------------------------------------')\n",
    "\n",
    "\n",
    "print('---------------GBT best model-------------')\n",
    "print('maxIter - ', bestModel_gbt.getOrDefault('maxIter'))\n",
    "print('maxDepth - ', bestModel_gbt.getOrDefault('maxDepth'))\n",
    "print('maxBins - ', bestModel_gbt.getOrDefault('maxBins'))\n",
    "print('------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "Start to train with best parameter...\n",
      "----------------------------------\n",
      "Random Forest execution time: 212.2647671699524\n",
      "GBT execution time: 2.8081161975860596\n"
     ]
    }
   ],
   "source": [
    "#training with whole data with best parameter\n",
    "print('----------------------------------')\n",
    "print('Start to train with best parameter...')\n",
    "print('----------------------------------')\n",
    "best_rf = RandomForestClassifier(featuresCol=\"features\",labelCol=\"labels\",\n",
    "                            numTrees = bestModel_rf.getNumTrees,\n",
    "                           maxDepth = bestModel_rf.getOrDefault('maxDepth'),\n",
    "                           maxBins = bestModel_rf.getOrDefault('maxBins'))\n",
    "\n",
    "best_gbt = GBTClassifier(featuresCol=\"features\",labelCol=\"labels\",\n",
    "                        maxIter=bestModel_gbt.getOrDefault('maxIter'),\n",
    "                        maxDepth = bestModel_gbt.getOrDefault('maxDepth'),\n",
    "                        maxBins = bestModel_gbt.getOrDefault('maxBins'))\n",
    "\n",
    "new_data = data.sample(False, 0.005,47)\n",
    "(trainingData, testData) = new_data.randomSplit([0.8, 0.2],47)\n",
    "\n",
    "trainingData.cache()\n",
    "testData.cache()\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "best_rfModel = best_rf.fit(trainingData)\n",
    "best_rf_predictions = best_rfModel.transform(testData)\n",
    "end = time.time()\n",
    "print('Random Forest execution time:',end-start)\n",
    "\n",
    "start = time.time()\n",
    "best_gbtModel = best_gbt.fit(trainingData)\n",
    "best_gbt_predictions = best_gbtModel.transform(testData)\n",
    "end = time.time()\n",
    "print('GBT execution time:',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Random Forest Score-----\n",
      "accuracy score: 0.685397378311486\n",
      "AUC score: 0.7474682491901027\n",
      "                             \n",
      "--------GBT Score------------\n",
      "accuracy score: 0.6545971216426804\n",
      "AUC score: 0.7161060715676998\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"labels\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "rf_accuracy_score = evaluator.evaluate(best_rf_predictions)\n",
    "\n",
    "gbt_accuracy_score = evaluator.evaluate(best_gbt_predictions)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"labels\",rawPredictionCol='rawPrediction', metricName=\"areaUnderROC\")\n",
    "\n",
    "rf_auc_score = evaluator.evaluate(best_rf_predictions)\n",
    "\n",
    "gbt_auc_score = evaluator.evaluate(best_gbt_predictions)\n",
    "\n",
    "print('-----Random Forest Score-----')\n",
    "print('accuracy score:',rf_accuracy_score)\n",
    "print('AUC score:',rf_auc_score)\n",
    "print('                             ')\n",
    "print('--------GBT Score------------')\n",
    "print('accuracy score:',gbt_accuracy_score)\n",
    "print('AUC score:',gbt_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------The most relevant Feature in random forest model---------\n",
      "        relevance\n",
      "m_bb     0.324462\n",
      "m_wwbb   0.140082\n",
      "m_wbb    0.119549\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "importances = best_rfModel.featureImportances\n",
    "df_relevance = pd.DataFrame(importances.toArray())\n",
    "df_relevance.columns = ['relevance']\n",
    "df_relevance.index = feature_names\n",
    "print('-------The most relevant Feature in random forest model---------')\n",
    "print(df_relevance.sort_values(by=['relevance'], ascending=False).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------The most relevant Feature in GBT model--------------------\n",
      "          relevance\n",
      "m_wwbb     0.196856\n",
      "jet 1 pt   0.178697\n",
      "m_jjj      0.173763\n"
     ]
    }
   ],
   "source": [
    "importances = best_gbtModel.featureImportances\n",
    "df_relevance = pd.DataFrame(importances.toArray())\n",
    "df_relevance.columns = ['relevance']\n",
    "df_relevance.index = feature_names\n",
    "print('-------The most relevant Feature in GBT model--------------------')\n",
    "print(df_relevance.sort_values(by=['relevance'], ascending=False).head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
