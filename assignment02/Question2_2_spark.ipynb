{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row,Column\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from pyspark.sql.functions import when,log,exp\n",
    "from pyspark.ml.feature import StringIndexer,OneHotEncoderEstimator\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[2]\") \\\n",
    "    .appName(\"COM6012 Assignment Task2\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\")\\\n",
    "    .config(\"spark.executor.cores\", 8)\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"OFF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start Data pre-processing\n",
    "raw_df = spark.read.csv('./Dataset/ClaimPredictionChallenge/train_set.csv',header= True)\n",
    "\n",
    "raw_df =raw_df.select('Vehicle','Var1','Var2','Var3','Var4','Var5','Var6','Var7','Var8','NVVar1','NVVar2','NVVar3','NVVar4',\n",
    "                  'Cat1','Cat2','Cat3','Cat4','Cat5','Cat6','Cat7','Cat8','Cat9','Cat10','Cat11','Cat12','Calendar_Year','Model_Year','Claim_Amount')\n",
    "\n",
    "for col in raw_df.columns:\n",
    "    raw_df = raw_df.filter((raw_df[col] != '?'))\n",
    "    \n",
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "double_data = ['Var1','Var2','Var3','Var4','Var5','Var6','Var7','Var8','NVVar1','NVVar2','NVVar3','NVVar4']\n",
    "int_data = ['Vehicle','Calendar_Year','Model_Year','Claim_Amount']\n",
    "input_features = double_data+int_data\n",
    "for col in double_data:\n",
    "    raw_df = raw_df.withColumn(col, raw_df[col].cast(DoubleType()))\n",
    "for col in int_data:\n",
    "    raw_df = raw_df.withColumn(col, raw_df[col].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = raw_df.withColumn(int_data[1], (raw_df[int_data[1]]-2005))\n",
    "raw_df = raw_df.withColumn(int_data[2], (raw_df[int_data[2]]-1981))\n",
    "\n",
    "#categorical Nbr Lvls in Train for each cat\n",
    "categorical_features = {'Cat1':11,'Cat2':4,'Cat3':7,'Cat4':4,'Cat5':4,'Cat6':7,'Cat7':5,'Cat8':4,'Cat9':2,'Cat10':4,'Cat11':7,'Cat12':7}\n",
    "\n",
    "for col,num in categorical_features.items():\n",
    "    name = col+'_id'\n",
    "    indexer = StringIndexer(inputCol=col, outputCol=name)\n",
    "    raw_df = indexer.fit(raw_df).transform(raw_df)\n",
    "\n",
    "raw_df = raw_df.select('Var1','Var2','Var3','Var4','Var5','Var6','Var7','Var8',\\\n",
    "                        'NVVar1','NVVar2','NVVar3','NVVar4',\\\n",
    "                        'Cat1_id','Cat2_id','Cat3_id','Cat4_id','Cat5_id','Cat6_id','Cat7_id','Cat8_id','Cat9_id','Cat10_id','Cat11_id','Cat12_id',\\\n",
    "                        'Calendar_Year','Model_Year','Claim_Amount')\n",
    "\n",
    "category_id = ['Cat1_id','Cat2_id','Cat3_id','Cat4_id','Cat5_id','Cat6_id','Cat7_id','Cat8_id','Cat9_id','Cat10_id','Cat11_id','Cat12_id']\n",
    "\n",
    "cat_ohe = []\n",
    "for col in category_id:\n",
    "    cat_ = col.replace('_id','_ohe')\n",
    "    cat_ohe.append(cat_)\n",
    "    input_features.append(cat_)\n",
    "\n",
    "\n",
    "data = raw_df.select('Var1','Var2','Var3','Var4','Var5','Var6','Var7','Var8','NVVar1','NVVar2','NVVar3','NVVar4',\n",
    "                  'Cat1_id','Cat2_id','Cat3_id','Cat4_id','Cat5_id','Cat6_id','Cat7_id','Cat8_id','Cat9_id','Cat10_id','Cat11_id','Cat12_id','Calendar_Year','Model_Year','Claim_Amount')\n",
    "\n",
    "\n",
    "encoder = OneHotEncoderEstimator(inputCols=category_id, outputCols=cat_ohe)\n",
    "encoder_data = encoder.fit(data)\n",
    "data  = encoder_data.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = data .withColumn('weight',when((data['Claim_Amount'] != 0), 0.98).otherwise(0.02))\n",
    "data  = data .withColumn('not_zero',when((data['Claim_Amount'] != 0), 1).otherwise(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.select('Var1','Var2','Var3','Var4','Var5','Var6','Var7','Var8','NVVar1','NVVar2','NVVar3','NVVar4',\n",
    "                  'Cat1_ohe','Cat2_ohe','Cat3_ohe','Cat4_ohe','Cat5_ohe','Cat6_ohe','Cat7_ohe','Cat8_ohe','Cat9_ohe','Cat10_ohe','Cat11_ohe','Cat12_ohe','Calendar_Year','Model_Year','Claim_Amount','weight','not_zero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['Var1','Var2','Var3','Var4','Var5','Var6','Var7','Var8','NVVar1','NVVar2','NVVar3','NVVar4',\n",
    "                  'Cat1_ohe','Cat2_ohe','Cat3_ohe','Cat4_ohe','Cat5_ohe','Cat6_ohe','Cat7_ohe','Cat8_ohe','Cat9_ohe','Cat10_ohe','Cat11_ohe','Cat12_ohe','Calendar_Year','Model_Year']\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "feat_assembler = VectorAssembler(inputCols = features_list, outputCol = 'features')\n",
    "data = feat_assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training......\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "import time\n",
    "data_logi= data.select('features','not_zero','weight','Claim_Amount')\n",
    "(trainingData, testData) = data_logi.randomSplit([0.7, 0.3], 47)\n",
    "\n",
    "trainingData.cache()\n",
    "testData.cache()\n",
    "\n",
    "#classification\n",
    "start = time.time()\n",
    "print('Start training......')\n",
    "logistic_Reg = LogisticRegression(labelCol ='not_zero',weightCol = 'weight',maxIter = 20)\n",
    "logisticReg_model1 = logistic_Reg.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticReg_prediction = logisticReg_model1.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "|not_zero|  count|\n",
      "+--------+-------+\n",
      "|       1|   8225|\n",
      "|       0|1111362|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logisticReg_prediction.groupBy('not_zero').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|prediction|  count|\n",
      "+----------+-------+\n",
      "|       0.0|1106126|\n",
      "|       1.0|  13461|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logisticReg_prediction.groupBy('prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_notzero = trainingData.filter('not_zero != 0')\n",
    "test_notzero = testData.filter('not_zero != 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 184.74051904678345\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "glm_poisson = GeneralizedLinearRegression(featuresCol='features', labelCol='Claim_Amount', maxIter=10, regParam=0.01,\\\n",
    "                                          family='Gamma', link='identity')\n",
    "\n",
    "glm_model = glm_poisson.fit(train_notzero)\n",
    "end = time.time()\n",
    "print('Execution time:',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_zero = logisticReg_prediction.filter('prediction == 0')\n",
    "pred_zero = pred_zero.withColumn('claim_prediction',pred_zero['not_zero']*0).select('Claim_Amount','claim_prediction')\n",
    "\n",
    "pred_nonzero = logisticReg_prediction.filter('prediction != 0')\n",
    "pred_nonzero = pred_nonzero.select('features','Claim_Amount')\n",
    "\n",
    "\n",
    "pred_amount = glm_model.transform(pred_nonzero)\n",
    "pred_amount = pred_amount.select('Claim_Amount','prediction')\n",
    "pred_amount = pred_amount.withColumnRenamed('prediction','claim_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pred_amount.union(pred_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.withColumn('Claim_Amount', result['Claim_Amount'].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 40.8206\n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"Claim_Amount\", predictionCol=\"claim_prediction\", metricName=\"rmse\")\n",
    "glm_rmse = evaluator.evaluate(result)\n",
    "print(\"RMSE = %g\" % glm_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
