{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution for Assignment 2 Question 2 Scalable ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Assignment2_Questions2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "sc.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data - Qs 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan, when, count, col\n",
    "\n",
    "df = spark.read.load(\"/data/ac1ash//train_set.csv\",format=\"csv\", inferSchema=\"true\", header=\"true\").cache()\n",
    "\n",
    "#Replace ?s with Nulls\n",
    "\n",
    "\n",
    "for i in df.columns:\n",
    "    df = df.withColumn(i,when((col(i)=='?'),None).otherwise(col(i)))\n",
    "    \n",
    "    \n",
    "#We get rid of the null data\n",
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with the categorical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer,VectorAssembler,Binarizer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "Num_Categorical = 12\n",
    "\n",
    "#We create some indexers so as to transform the categorical features\n",
    "#Here index_feature simply obtains the names of all the categorical features\n",
    "index_feature = df.columns[5:21]+df.columns[29:30]\n",
    "\n",
    "#The outputCol will retain the same name of each categorical feature adding \"_Num\" at\n",
    "#the end just to refer as the column feature that it is already transformed\n",
    "Indexers = [StringIndexer(inputCol=i, outputCol=i+\"_Num\") for i in index_feature]\n",
    "\n",
    "pipeline1 = Pipeline(stages=Indexers) #This pipeline is for transforming the categorical features\n",
    "\n",
    "#The following variable which_cols will keep all the names of the variables that where not categorical\n",
    "#and also the names of the new transformed features (say \"Cat1_Num\") that used to be categorical. \n",
    "which_cols= df.columns[1:5]+df.columns[21:29]+df.columns[30:34]+[\"Cat\"+str(i+1)+\"_Num\" for i in range(Num_Categorical)]\n",
    "which_cols = which_cols+[\"NVCat_Num\",\"Blind_Make_Num\",\"Blind_Model_Num\",\"Blind_Submodel_Num\",\"OrdCat_Num\"]\n",
    "\n",
    "#The intention is that which_cols indicates what are the final features to use for training purposes\n",
    "#The pipeline2 is to define the final features for training\n",
    "pipeline2 = Pipeline(stages=[VectorAssembler(inputCols=which_cols, outputCol=\"features\")]) \n",
    "\n",
    "#The pipeline3 is defined for defining a binary label so as to train a binary classifier\n",
    "#which decides in a first stage if a costumer might or not claim for money \n",
    "pipeline3 = Pipeline(stages=[Binarizer(threshold=0.0001, inputCol=\"Claim_Amount\", outputCol=\"label\")])\n",
    "\n",
    "#This is a pipeline to gather all pipelines\n",
    "pipeline = Pipeline(stages=[pipeline1,pipeline2,pipeline3])\n",
    "\n",
    "#We make the data go through the pipelines\n",
    "df_end = pipeline.fit(df).transform(df)\n",
    "\n",
    "#At this stage we have prepared our dataset\n",
    "transformed = df_end.select(['Row_ID','features','Claim_Amount','label'])\n",
    "df=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We create two dataframes with costumers which did claim and did not claim for money respectively\n",
    "claim_true=transformed.where(transformed[\"label\"]>0.0)\n",
    "claim_false=transformed.where(transformed[\"label\"]==0.0)\n",
    "\n",
    "relative_amount_toTake=0.8    #we will take 80% of data from costumer that did claim for money\n",
    "\n",
    "#portion_Tobalance refers to the relative percentage of data to take randomly\n",
    "#from the claim_false (costumers that did not claim money) in  order to have\n",
    "#balanced dataset, with almost the same number of data from costumers \n",
    "#who claim and the ones who did not claim\n",
    "portion_Tobalance=claim_true.count()*relative_amount_toTake/float(claim_false.count()) \n",
    "transformed=[]\n",
    "\n",
    "##We select a proper portion of data to represent the information \n",
    "##when the costumer claims for money for dealing with the unbalanced data\n",
    "(train_NoClaim, test_NoClaim) = claim_false.randomSplit([portion_Tobalance, 1.0-portion_Tobalance],seed=20) \n",
    "(train_Claim, test_Claim) = claim_true.randomSplit([relative_amount_toTake, 1.0-relative_amount_toTake],seed=20)\n",
    "\n",
    "#We join the training data for both types of costumers\n",
    "trainData = train_NoClaim.unionAll(train_Claim)\n",
    "#We join the testing data for both types of costumers\n",
    "testData = test_NoClaim.unionAll(test_Claim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Linear Regression Model Qs  2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training with Generalised Linear Models (Gaussian distribution)\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "glr = LinearRegression(maxIter=20, regParam=0.001)\n",
    "\n",
    "# Fit the model\n",
    "model = glr.fit(trainData)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.transform(trainData).show()\n",
    "\n",
    "# Select prediction and true label so as to compute training and test error\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "pred_train = model.transform(trainData)\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator.evaluate(pred_train)\n",
    "print(\"\\n\\n Mean Absolute Error (MAE) on train data = %g\\n\\n\" % mae)\n",
    "\n",
    "evaluator2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator2.evaluate(pred_train)\n",
    "print(\"\\n\\n Mean Sqaured Error (MSE) on train data = %g\\n\\n\" % mse)\n",
    "\n",
    "\n",
    "\n",
    "pred_test_claim = model.transform(test_Claim)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator.evaluate(pred_test_claim)\n",
    "print(\"\\n\\nMean Absolute Error (MAE) on test data costumers who claimed = %g\\n\\n\" % mae)\n",
    "\n",
    "evaluator1 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator2.evaluate(pred_test_claim)\n",
    "print(\"\\n\\nMean Sqaured Error (MSE) on test data costumers who claimed = %g\\n\\n\" % mse)\n",
    "\n",
    "print(\"Testing with costumer that actually claimed for money\\n\")\n",
    "#pred_test_claim.orderBy(\"label\",ascending=False).show(1000)\n",
    "\n",
    "pred_test_claim.describe().show()\n",
    "\n",
    "pred_test_Noclaim = model.transform(test_NoClaim)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator.evaluate(pred_test_Noclaim)\n",
    "print(\"\\n\\nMean Absolute Error (MAE) on test data costumers who did not claim = %g\\n\\n\" % mae)\n",
    "\n",
    "\n",
    "evaluator2 = RegressionEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"mse\")\n",
    "mse = evaluator.evaluate(pred_test_Noclaim)\n",
    "print(\"\\n\\nMean Sqaured Error (MSE) on test data costumers who did not claim = %g\\n\\n\" % mse)\n",
    "\n",
    "print(\"Testing with costumer that actually claimed for money\\n\")\n",
    "\n",
    "\n",
    "#pred_test_Noclaim.orderBy(\"label\",ascending=False).show(1000)\n",
    "\n",
    "pred_test_Noclaim.describe().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Logistic Regression Model: binary classification Qs 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=100, regParam=0.9)\n",
    "pipeline_lr = Pipeline(stages=[lr])\n",
    "model_bern = pipeline_lr.fit(trainData)\n",
    "print('Logistic those who claimed:\\n')\n",
    "model_bern.transform(test_Claim).show(100)\n",
    "print('Logistic for those who did not claim:\\n')\n",
    "model_bern.transform(test_NoClaim).show(100)\n",
    "###################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Gamma Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### We select the features and the proper label (Claim_Amount) #######\n",
    "trainData_gamma=train_Claim.select([\"Row_ID\",\"features\",\"Claim_Amount\"])\n",
    "trainData_gamma=trainData_gamma.withColumnRenamed(\"Claim_Amount\",\"label\")\n",
    "#trainData_gamma.show(100)\n",
    "testData_gamma=test_Claim.select([\"Row_ID\",\"features\",\"Claim_Amount\"])\n",
    "testData_gamma=testData_gamma.withColumnRenamed(\"Claim_Amount\",\"label\")\n",
    "#testData_gamma.show(100)\n",
    "\n",
    "from pyspark.ml.regression import GeneralizedLinearRegression\n",
    "glr = GeneralizedLinearRegression(family=\"gamma\", link=\"identity\", maxIter=100, regParam=0.001)\n",
    "\n",
    "# Fit the model\n",
    "model = glr.fit(trainData_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select prediction and true label so as to compute training and test error\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "pred_bern_Claim=model_bern.transform(test_Claim).withColumnRenamed(\"prediction\",\"pred_bern\")\n",
    "pred_bern_gamma_Claim=model.transform(pred_bern_Claim).withColumnRenamed(\"prediction\",\"pred_gamma\")\n",
    "final_pred_Claim = pred_bern_gamma_Claim.select(\"Row_ID\",\"Claim_Amount\",\"pred_bern\",\"pred_gamma\",(pred_bern_gamma_Claim.pred_bern*pred_bern_gamma_Claim.pred_gamma).alias(\"prediction\"))\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Claim_Amount\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator.evaluate(final_pred_Claim)\n",
    "print(\"\\n\\nThe MAE for Bernoulli+Gamma Model on test data costumer who claimed = %g\\n\\n\" % mae)\n",
    "final_pred_Claim.orderBy(\"Claim_Amount\",ascending=False).show(1000)\n",
    "\n",
    "### We can check some statistics of the results for those who claimed\n",
    "final_pred_Claim.describe().show()\n",
    "\n",
    "pred_bern_NoClaim=model_bern.transform(test_NoClaim).withColumnRenamed(\"prediction\",\"pred_bern\")\n",
    "pred_bern_gamma_NoClaim=model.transform(pred_bern_NoClaim).withColumnRenamed(\"prediction\",\"pred_gamma\")\n",
    "final_pred_NoClaim = pred_bern_gamma_NoClaim.select(\"Row_ID\",\"Claim_Amount\",\"pred_bern\",\"pred_gamma\",(pred_bern_gamma_NoClaim.pred_bern*pred_bern_gamma_NoClaim.pred_gamma).alias(\"prediction\"))\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol=\"Claim_Amount\", predictionCol=\"prediction\", metricName=\"mae\")\n",
    "mae = evaluator.evaluate(final_pred_NoClaim)\n",
    "print(\"\\n\\nThe MAE for Bernoulli+Gamma Model on test data costumer who did not claim = %g\\n\\n\" % mae)\n",
    "final_pred_NoClaim.orderBy(\"Claim_Amount\",ascending=False).show(1000)\n",
    "\n",
    "### We can check some statistics of the results for those who did not claim\n",
    "final_pred_NoClaim.describe().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
